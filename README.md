# Nash Equilibria

A game can be represented by:

* Players $$N = \{1, \cdots n \}$$
* Actions ‚Üí players can do something to affect the world
* Outcomes ‚Üí players‚Äô actions lead to outcomes
* Preferences over outcomes ‚Üí each player $$p_i$$ has a preferences / ranking of the outcomes (in terms of utility)

This provides a general, abstract framework for **strategic interaction**.

### Pure Nash Equilibrium

Given everyone else‚Äôs actions $$\vec a_{-i}$$, the **best response** set of player $$i$$ is:

$$
BR_i(\vec a_{-i}) = \{ b \in A_i | b \in \argmax u_i(\vec a_{-i}, b) \}
$$

That is, a player $$i$$‚Äôs best response can be any of the actions that give him the maximum possible utility, given everyone else‚Äôs actions.

An action profile $$\vec a$$ is a (pure) Nash equilibrium if:

$$
\forall i \in N, a_i \in BR_i(\vec a_{-i})
$$

That is, every player has picked their best response given everyone else‚Äôs actions. You can also think of it as: each player picks the action as if they were the last one to do so, and they knew everyone else‚Äôs actions.

> _Every player thinks ‚ÄúI‚Äôm doing the best I can, given everyone else‚Äôs actions.‚Äù_

### Mixed Nash Equilibrium

Instead of choosing a single action, one can play a random mix of them (to be unpredictable, otherwise if someone knows you well): $$\vec p_i \in \Delta(A_i)$$ is a probability distribution (from the set of all possible probability distributions) over player $$i$$‚Äôs actions.

(Note: In general, we use $$\Delta(X)$$ to represent the set of all possible distributions over X)

A (not necessarily pure) strategy profile can be represented as:

$$
\vec p = (\vec p_1, \cdots, \vec p_n) \in \Delta(A_1) \times \cdots \times \Delta(A_n)
$$

Then, a player‚Äôs utility (for a given mixed strategy) is given by:

$$
u_i(\vec p) = \sum_{\vec a \in A} u_i(\vec a)\Pr[\vec a] = E_{\vec a \sim \vec p}[u_i(\vec a)]
$$

In particular, note that the player‚Äôs ONLY care about the **expected value** of their strategy, NOT the variance / risk that their strategy runs. e.g. they would be indifferent to a strategy that guarantees them $50 vs. flipping a coin for $100  ‚Äî both have the same expected value, and being ‚Äúrisk-neutral‚Äù, they wouldn‚Äôt care which one they did. That is, they are neutral / indifferent to risk ‚Üí they don‚Äôt care if they take risk or don‚Äôt (they don‚Äôt avoid it - by taking the gauranteed money - nor do they seek it - by taking the coin flip; they‚Äôre just indifferent).

Then, $$\vec p$$ is a (not necessarily pure) nash equilibrium is when: for all players $$i \in N$$, and all possible strategy (possibly containing mixed actions) of each player $$q_i \in \Delta(A_i)$$, $$u_i(\vec p) \geq u_i(\vec p_{-i}, \vec q_i)$$ ‚Üí their current strategy is at least as good as any other.

In these notes, we use ‚Äúaction‚Äù to refer to a pure strategy (only one possible action, played with probability = 1), and the general term ‚Äústrategy‚Äù to refer to possibly mixed actions (i.e., playing multiple actions, each with some probability)

{% hint style="warning" %}
**Nash‚Äôs Theorem**: Unlike a _pure_ Nash Equilibrium, a (not necessarily pure) Nash Equilibrium ALWAYS EXISTS.
{% endhint %}

The way to compute nash equilibria in a 2x2 games (2 players, each have 2 actions) is by considering 2 possible cases:

1. Case 1 ‚Üí Compute all NE (if any) in which at least one player plays a pure strategy (do this exhaustively, e.g. ‚Äúrow player plays action X while col player mixes between A and B with probability q and (1-q), then find the value(s) of q for which the best response is X ‚Äî then you‚Äôve found a NE)
2. Case 2 ‚Üí Compute all NE (if any) in which both players mix between both strategies

Nash‚Äôs theorem says that the union of the set of NE‚Äôs found in case 1 and case 2 is non-empty ‚Üí it doesn‚Äôt say whether the NE is pure / not.

The key idea behind case 2 is that the only time that a player would mix between 2 strategies is when (given the opponent‚Äôs strategy), he is indifferent to his 2 actions. That is, no matter what action he picks, his utility is the same _given the opponent‚Äôs strategy_. This allows us to equate the expected utilities of the two actions for player 1, to find the ‚Äúmixing probabilities‚Äù for player 2 üò≤ (and vice versa).

### Dominant Strategies

We say that a strategy $$\vec p \in \Delta(A_i)$$ (weakly) dominates $$\vec q \in \Delta(A_i)$$ if:

$$
\forall \vec p_{-i} \in \Delta(A_{-i}) : u_i(\vec p_{-i}, \vec p) \geq u_i(\vec p_{-i}, \vec q)
$$

In words: no matter what everyone else does, picking $$\vec p$$ is at least as good as picking $$\vec q$$.

**Strict** domination is when $$u_i(\vec p_{-i}, \vec p) > u_i(\vec p_{-i}, \vec q)$$ for every $$\vec p_{-i}$$ ‚Üí no matter what everyone else does, strategy $$\vec p$$ is STRICTLY better than $$\vec q$$ (and so, you should never even consider picking $$\vec q$$ !!).

{% hint style="warning" %}
**Theorem**: If an action $$a \in A_i$$ is STRICTLY dominated by some strategy $$\vec p \in \Delta(A_i)$$, then action $$a$$ is NEVER PLAYED with any positive probability in ANY Nash equilibrium.
{% endhint %}

Intuitively, if you would move all the probability out of the lamer / weaker actions into the ones that dominate it, and you strictly increase your utility. Hence, picking $$a$$ (with any non-zero probability) can never be a ‚Äúbest‚Äù response ü§Ø

**Iterated Removal of Strictly Dominated Strategies**

If you‚Äôre trying to find Nash Equilibria, then you can remove action profiles that contain a strictly dominated strategy (from either player‚Äôs side).

Note:

* This ONLY works if the action is _strictly_ dominated by another strategy (can be a strategy involving multiple actions ‚Äî using mixed probabilities too)
* If you‚Äôre left with a single action / strategy profile at the end, then by Nash Theorem, it must be a NE.
* The reason this works is simply because those cells which contain a strictly dominated strategy (from either player‚Äôs side) are never going to happen, i.e., they can never be an equilibrium (because at least one player would change their strategy to the one which strictly dominates it)
* When considrering whether a strategy $$S$$ (may be mixed) strictly dominates an action $$P$$ for the row player, we don‚Äôt have to consider all possible strategies of the col player ‚Äî we can just look at the individual actions and ensure that $$S$$ strictly dominates $$P$$ for every action. Then, since any strategy is a linear combination of actions, if $$S$$ strictly beats $$P$$ for every action of the col player, then $$S$$ strictly beats $$P$$ for every strategy involving those actions too. (Moreover, we only have to lok at the actions of the col players that are not already strictly dominated by other strategies ‚Äî since col player would not play the weaker actions otherwise).



